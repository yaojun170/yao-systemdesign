# Raft 共识算法设计文档

## 一、为什么需要共识算法？

### 1.1 核心问题：分布式系统的本质挑战

在分布式系统中，我们面临三个无法逃避的现实：

```
┌────────────────────────────────────────────────────────────────┐
│                    分布式系统的三大挑战                         │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  1️⃣ 网络不可靠                                                 │
│     • 消息可能丢失、重复、乱序、延迟                            │
│     • 无法区分"对方宕机"和"网络断开"                           │
│                                                                │
│  2️⃣ 节点可能故障                                               │
│     • 随时可能崩溃、重启                                       │
│     • 时钟不同步、性能波动                                     │
│                                                                │
│  3️⃣ 没有全局时钟                                               │
│     • 无法确定事件的绝对顺序                                   │
│     • "同时发生"这个概念在分布式系统中没有意义                  │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

### 1.2 没有共识算法会怎样？

让我们看几个"朴素方案"为什么会失败：

#### ❌ 方案一：简单复制

```
客户端 → 写入 Node1 → 同步到 Node2, Node3

问题场景：
1. 客户端写入 Node1: x=1
2. Node1 同步给 Node2 成功
3. Node1 同步给 Node3 时网络断开
4. Node1 宕机

结果：Node2 有 x=1，Node3 没有
      谁是对的？如何恢复？
```

#### ❌ 方案二：主从复制

```
客户端 → 主节点 → 同步到从节点

问题场景（脑裂）：
1. 主节点 M 和从节点 S1, S2
2. 网络分区：M 和 S1 在一边，S2 在另一边
3. S2 认为 M 挂了，自己升级为主
4. 现在有两个主节点！

结果：数据分叉，无法自动修复
```

#### ❌ 方案三：全部确认再提交

```
客户端 → 写入所有节点 → 全部成功才返回

问题：
1. 任何一个节点故障，整个系统不可用
2. 可用性 = 单节点可用性^N（指数下降）
3. 3 节点 99.9% → 整体只有 99.7%
```

#### ❌ 方案四：多数派确认

```
3 个节点，2 个确认就返回成功

问题场景：
1. 客户端 A 写入 x=1，Node1 和 Node2 确认
2. 客户端 B 写入 x=2，Node2 和 Node3 确认
3. Node2 宕机重启

结果：x 是 1 还是 2？没有全局顺序！
```

### 1.3 问题的本质：FLP 不可能定理

1985 年 Fischer、Lynch、Paterson 证明了：

> **在异步网络中，只要有一个节点可能故障，就不存在一个确定性算法能保证共识。**

```
┌──────────────────────────────────────────────────────────────┐
│                     FLP 不可能定理                           │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  在以下条件下，共识问题无解：                                 │
│  • 异步网络（消息延迟无上界）                                 │
│  • 至少一个节点可能故障                                       │
│  • 需要确定性终止                                            │
│                                                              │
│  直观理解：                                                  │
│  你永远无法区分"对方在思考"和"对方已经死了"                   │
│  如果等太久 → 系统卡住（活性问题）                            │
│  如果不等 → 可能做出错误决定（安全性问题）                    │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

### 1.4 共识算法如何破局？

共识算法（如 Raft、Paxos）通过**放宽条件**来绕过 FLP 不可能定理：

| 方法 | 说明 | 代表算法 |
|------|------|---------|
| **随机化** | 引入随机超时，打破对称性 | Raft（随机选举超时） |
| **弱化活性** | 不保证一定终止，但保证安全 | Paxos |
| **部分同步假设** | 假设最终网络会恢复 | 大多数实用算法 |

---

## 二、共识算法解决了什么问题？

### 2.1 共识的形式化定义

共识算法需要满足三个属性：

```
┌──────────────────────────────────────────────────────────────┐
│                    共识的三个核心属性                         │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  1️⃣ 一致性（Agreement）                                       │
│     所有正确的节点最终决定相同的值                             │
│                                                              │
│  2️⃣ 有效性（Validity）                                        │
│     决定的值必须是某个节点提议的值                             │
│     （不能凭空造出一个值）                                    │
│                                                              │
│  3️⃣ 终止性（Termination）                                     │
│     所有正确的节点最终会做出决定                              │
│     （不会永远卡住）                                          │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

### 2.2 Raft 如何实现这三个属性

```
┌─────────────────────────────────────────────────────────────────┐
│                    Raft 的解决方案                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  一致性保证：                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  • 单一 Leader：所有决定由 Leader 做出                    │   │
│  │  • 多数派提交：超过半数确认才算提交                       │   │
│  │  • 日志匹配：相同位置必须是相同内容                       │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  有效性保证：                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  • 只有客户端提议的命令才会被记录                         │   │
│  │  • Leader 只追加日志，不篡改                              │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
│  终止性保证：                                                   │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  • 随机选举超时：避免活锁                                 │   │
│  │  • 心跳机制：快速检测故障                                 │   │
│  │  • 部分同步假设：假设网络最终会恢复                       │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 三、Raft 核心机制详解

### 3.1 Leader 选举

#### 为什么需要 Leader？

```
没有 Leader 的问题：
┌─────────┐     ┌─────────┐     ┌─────────┐
│ Node A  │     │ Node B  │     │ Node C  │
│ 提议x=1 │     │ 提议x=2 │     │ 提议x=3 │
└────┬────┘     └────┬────┘     └────┬────┘
     │               │               │
     └───────────────┼───────────────┘
                     ▼
           谁的提议算数？需要投票！
           但如果每次都投票，效率太低

有 Leader 的好处：
┌─────────┐     ┌─────────┐     ┌─────────┐
│ Leader  │────▶│Follower │     │Follower │
│ 我说了算│     │ 听指挥  │     │ 听指挥  │
└─────────┘     └─────────┘     └─────────┘
     │
     ▼
  所有决策通过我
  只需选举一次
```

#### 选举流程

```
时间轴 ─────────────────────────────────────────────▶

状态：    [Follower]──超时──▶[Candidate]──得票──▶[Leader]
                                  │
                                  ├── 发现更高 term ──▶[Follower]
                                  │
                                  └── 选举超时 ──▶[Candidate]（重试）

关键点：
1. 随机超时（150-300ms）防止同时发起选举
2. 每个节点每个 term 只能投一票
3. 获得多数派投票才能成为 Leader
4. 发现更高 term 立即退回 Follower
```

#### 投票规则（确保安全性）

```java
// 接收 RequestVote 时的判断逻辑
boolean shouldGrantVote(RequestVote request) {
    // 1. 任期检查：落后的候选人不能当选
    if (request.term < currentTerm) {
        return false;
    }
    
    // 2. 投票状态：每个 term 只投一票
    if (votedFor != null && !votedFor.equals(request.candidateId)) {
        return false;
    }
    
    // 3. 日志检查：候选人日志必须"至少一样新"
    //    这保证了已提交的日志不会丢失！
    boolean candidateLogUpToDate = 
        (request.lastLogTerm > myLastLogTerm) ||
        (request.lastLogTerm == myLastLogTerm && 
         request.lastLogIndex >= myLastLogIndex);
    
    return candidateLogUpToDate;
}
```

### 3.2 日志复制

#### 复制流程

```
┌──────────────────────────────────────────────────────────────┐
│                      日志复制完整流程                         │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  Client                                                      │
│    │ ① SET x=1                                               │
│    ▼                                                         │
│  [Leader]                                                    │
│    │ ② 追加到本地日志 (index=5, term=3, uncommitted)         │
│    │                                                         │
│    ├─────────────────┬─────────────────┐                    │
│    │                 │                 │                    │
│    ▼                 ▼                 ▼                    │
│ [Follower1]     [Follower2]     [Follower3]                │
│    │                 │                 │                    │
│    │ ③ AppendEntries(prevLogIndex=4, prevLogTerm=2, ...)   │
│    │                 │                 │                    │
│    │ ④ 检查 prevLog 是否匹配                                │
│    │    ✓ 匹配 → 追加                                       │
│    │    ✗ 不匹配 → 拒绝                                     │
│    │                 │                 │                    │
│    └────── ACK ──────┴────── ACK ──────┘                    │
│                      │                                       │
│                      ▼                                       │
│  [Leader] ⑤ 收到多数派 ACK (2+1=3 >= 2)                     │
│    │                                                         │
│    │ ⑥ 提交日志 (commitIndex = 5)                           │
│    │                                                         │
│    │ ⑦ 应用到状态机，返回客户端                              │
│    │                                                         │
│    │ ⑧ 下次心跳携带 leaderCommit=5                          │
│    ▼                                                         │
│  [Followers] 更新自己的 commitIndex，应用到状态机            │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

#### 一致性保证：Log Matching Property

```
核心规则：
如果两个日志在某个 index 的 entry 有相同的 term，
那么这两个日志在这个 index 之前的所有 entry 都相同。

实现方式：
┌─────────────────────────────────────────────────────────────┐
│  AppendEntries 请求携带：                                    │
│  • prevLogIndex: 新条目前一条的索引                          │
│  • prevLogTerm:  新条目前一条的任期                          │
│                                                             │
│  Follower 检查：                                            │
│  if (log[prevLogIndex].term != prevLogTerm) {               │
│      return REJECT; // 日志不一致，需要回退                  │
│  }                                                          │
│                                                             │
│  Leader 收到 REJECT 后：                                    │
│  nextIndex[follower]--; // 回退一步                         │
│  retry();               // 重新发送更早的日志                │
└─────────────────────────────────────────────────────────────┘

示例：
Leader 日志:    [1:a] [1:b] [2:c] [3:d] [3:e]
                  1     2     3     4     5

Follower 日志:  [1:a] [1:b] [2:x]    <- 不一致！
                  1     2     3

修复过程：
1. Leader 发送 prevLogIndex=4, prevLogTerm=3 → Follower 拒绝
2. Leader 发送 prevLogIndex=3, prevLogTerm=2 → Follower 拒绝
3. Leader 发送 prevLogIndex=2, prevLogTerm=1 → Follower 接受
4. Leader 发送 index 3,4,5 的日志，Follower 覆盖
```

### 3.3 安全性保证

#### Leader 完整性（Leader Completeness）

```
定理：如果一条日志在某个 term 被提交，那么这条日志一定出现在
     所有更高 term 的 Leader 的日志中。

证明思路：
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  假设 entry E 在 term T 被提交：                             │
│  • E 被复制到了多数派节点                                   │
│                                                             │
│  假设节点 N 在 term T' > T 成为 Leader：                    │
│  • N 获得了多数派的投票                                     │
│  • 投票给 N 的多数派 ∩ 有 E 的多数派 ≠ ∅                   │
│  • 所以至少有一个投票者有 E                                 │
│  • 投票规则：候选人日志必须 >= 投票者                        │
│  • 所以 N 一定有 E                                          │
│                                                             │
│  关键洞察：两个多数派一定有交集！                            │
│  ┌─────────────────────┐                                   │
│  │    多数派1           │                                   │
│  │  ┌───────┐          │                                   │
│  │  │ 交集  │ 多数派2   │                                   │
│  │  └───────┘          │                                   │
│  └─────────────────────┘                                   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 四、Raft 的实际应用

### 4.1 典型应用场景

| 场景 | 说明 | 代表系统 |
|------|------|---------|
| **元数据存储** | 集群配置、路由信息 | etcd, Consul |
| **分布式锁** | 需要强一致性的协调服务 | etcd |
| **分布式数据库** | 每个分片一个 Raft 组 | TiKV, CockroachDB |
| **消息队列** | 日志/消息的可靠存储 | Kafka (KRaft) |
| **配置中心** | 配置的强一致分发 | Nacos, Apollo |

### 4.2 适用条件

```
✅ 适合使用 Raft：
├── 需要强一致性（线性一致性）
├── 节点数量适中（3-7 个最佳，推荐奇数）
├── 同机房/低延迟网络
├── 元数据/配置类场景（写少读多）
└── 对数据可靠性要求极高

❌ 不适合使用 Raft：
├── 节点数量很大（>10）
├── 跨地域/高延迟网络
├── 高写入吞吐量场景
├── 只需要最终一致性
└── 对可用性要求高于一致性（CAP 的 AP）
```

### 4.3 性能特点

```
写入延迟 = 网络 RTT × 2 + 日志落盘时间
         = Leader 到 Follower RTT + Follower 响应 RTT + fsync

典型延迟：
• 同机房：1-5ms
• 同地域：5-20ms  
• 跨地域：50-200ms（不推荐）

吞吐量瓶颈：
• 单 Leader 处理所有写请求
• 可通过 Multi-Raft（多个 Raft 组）横向扩展
```

---

## 五、Raft vs 其他方案对比

### 5.1 与简单主从复制对比

| 维度 | Raft | 主从复制 |
|------|------|---------|
| 脑裂处理 | ✅ 任期机制自动解决 | ❌ 需要人工介入或外部仲裁 |
| 数据丢失 | ✅ 多数派确认不丢失 | ❌ 主节点故障可能丢失 |
| 故障恢复 | ✅ 自动选举新 Leader | ❌ 需要人工提升从节点 |
| 复杂度 | 中等 | 低 |

### 5.2 与 Paxos 对比

| 维度 | Raft | Paxos |
|------|------|-------|
| 可理解性 | ⭐⭐⭐⭐⭐ | ⭐⭐ |
| Leader 机制 | 强制 | 可选（Multi-Paxos） |
| 日志连续性 | 必须连续 | 可有空洞 |
| 工程实现 | 较简单 | 较复杂 |
| 理论完备性 | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |

### 5.3 与 ZAB 对比

| 维度 | Raft | ZAB |
|------|------|-----|
| 设计目标 | 通用共识 | ZooKeeper 专用 |
| 恢复阶段 | 简单 | Discovery + Sync |
| 提交确认 | 隐式（心跳携带） | 显式 COMMIT 消息 |
| 应用场景 | 通用 | 配置/协调 |

---

## 六、核心要点总结

```
┌────────────────────────────────────────────────────────────────┐
│                    为什么需要共识算法？                         │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  🔴 分布式系统的本质问题：                                      │
│     • 网络不可靠，消息可能丢失/延迟                             │
│     • 节点可能故障，无法区分故障和网络分区                      │
│     • 没有全局时钟，无法确定事件顺序                            │
│                                                                │
│  🔴 简单方案的失败：                                            │
│     • 简单复制：故障后不知道谁是权威                            │
│     • 主从复制：可能脑裂，两个主节点                            │
│     • 全部确认：任一故障导致不可用                              │
│     • 多数派确认：没有全局顺序                                  │
│                                                                │
│  🟢 共识算法的价值：                                            │
│     • 一致性：所有节点最终达成相同决定                          │
│     • 容错性：少数节点故障不影响系统                            │
│     • 自动恢复：故障后自动选举新 Leader                         │
│                                                                │
│  🟢 Raft 的核心机制：                                           │
│     • Leader 选举：随机超时 + 多数派投票                        │
│     • 日志复制：一致性检查 + 回退重试                           │
│     • 安全性：日志匹配 + Leader 完整性                          │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

## 七、本项目的 Raft 实现

本项目在 `cn.yj.sd.raft` 包中实现了完整的 Raft 协议，包括：

- **Leader 选举**：随机超时、任期机制、多数派投票
- **日志复制**：心跳机制、一致性检查、自动回退
- **状态机**：简单的 KV 存储

运行演示：
```bash
mvn exec:java -Dexec.mainClass="cn.yj.sd.raft.demo.RaftClusterDemo"
```
